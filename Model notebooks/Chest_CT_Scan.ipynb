{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NzJ9TkiAPuiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhovYWvPchHX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50, EfficientNetB0, InceptionV3\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def define_paths(dir):\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "    folds = os.listdir(dir)\n",
        "    for fold in folds:\n",
        "        foldpath = os.path.join(dir, fold)\n",
        "        filelist = os.listdir(foldpath)\n",
        "        for file in filelist:\n",
        "            fpath = os.path.join(foldpath, file)\n",
        "            filepaths.append(fpath)\n",
        "            labels.append(fold)\n",
        "    return filepaths, labels\n",
        "def define_df(files, classes):\n",
        "    Fseries = pd.Series(files, name= 'filepaths')\n",
        "    Lseries = pd.Series(classes, name='labels')\n",
        "    return pd.concat([Fseries, Lseries], axis= 1)\n",
        "\n",
        "def create_df(tr_dir, val_dir, ts_dir):\n",
        "    # train dataframe\n",
        "    files, classes = define_paths(tr_dir)\n",
        "    train_df = define_df(files, classes)\n",
        "\n",
        "    # validation dataframe\n",
        "    files, classes = define_paths(val_dir)\n",
        "    valid_df = define_df(files, classes)\n",
        "    # test dataframe\n",
        "    files, classes = define_paths(ts_dir)\n",
        "    test_df = define_df(files, classes)\n",
        "    return train_df, valid_df, test_df"
      ],
      "metadata": {
        "id": "GvigYtlZIBuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_gens(train_df, valid_df, test_df, batch_size):\n",
        "    img_size = (224, 224)\n",
        "    channels = 3\n",
        "    img_shape = (img_size[0], img_size[1], channels)\n",
        "    ts_length = len(test_df)\n",
        "    test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
        "    test_steps = ts_length // test_batch_size\n",
        "    def scalar(img):\n",
        "        return img\n",
        "    tr_gen = ImageDataGenerator(preprocessing_function= scalar, horizontal_flip= True)\n",
        "    ts_gen = ImageDataGenerator(preprocessing_function= scalar)\n",
        "    train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                        color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "    valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                        color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "    test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                        color_mode= 'rgb', shuffle= False, batch_size= test_batch_size)\n",
        "    return train_gen, valid_gen, test_gen"
      ],
      "metadata": {
        "id": "fWJJl1c_IC4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load and Preprocess Dataset**\n",
        "\n",
        "Assuming you have your dataset in different folders for each class, use ImageDataGenerator to load and preprocess the data:"
      ],
      "metadata": {
        "id": "pkv2JHN9eRue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Dataframes\n",
        "train_dir = '/content/drive/MyDrive/DSE Project/Data/train'\n",
        "test_dir = '/content/drive/MyDrive/DSE Project/Data/test'\n",
        "valid_dir = '/content/drive/MyDrive/DSE Project/Data/valid'\n",
        "train_df, valid_df, test_df = create_df(train_dir, valid_dir, test_dir)\n",
        "\n",
        "# Get Generators\n",
        "batch_size = 40\n",
        "train_data, valid_data, test_data = create_gens(train_df, valid_df, test_df, batch_size)"
      ],
      "metadata": {
        "id": "98LLeehqINnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize Data Composition**\n"
      ],
      "metadata": {
        "id": "pH8aawuuetLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming train_data.class_indices provides class names and train_data.labels gives label counts\n",
        "labels = list(train_data.class_indices.keys())\n",
        "class_counts = train_data.labels\n",
        "\n",
        "# Plotting dataset composition\n",
        "sns.countplot(x=class_counts)\n",
        "plt.title('Dataset Composition')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.xticks(np.arange(len(labels)), labels, rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xqLHERWYewRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the Models (ResNet50, EfficientNetB0, InceptionV3)**\n",
        "\n",
        "Create models using ResNet50, EfficientNetB0, and InceptionV3 as base models:"
      ],
      "metadata": {
        "id": "-ahAApHkezwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(base_model):\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dropout(0.5),\n",
        "        Dense(4, activation='softmax')  # 4 classes: adenocarcinoma, large-cell, squamous-cell, normal\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create base models with pre-trained weights\n",
        "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "efficientnet_base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "inceptionv3_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "densenet_base = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "resnet_model = build_model(resnet_base)\n",
        "efficientnet_model = build_model(efficientnet_base)\n",
        "inceptionv3_model = build_model(inceptionv3_base)\n",
        "densenet_base = build_model(densenet_base)"
      ],
      "metadata": {
        "id": "6oprvfqIe5VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trian the models**"
      ],
      "metadata": {
        "id": "-boa7done9BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_data.classes),\n",
        "    y=train_data.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Training ResNet50\n",
        "resnet_history = resnet_model.fit(train_data, validation_data=valid_data, epochs=50, class_weight=class_weights)\n",
        "\n",
        "# Training EfficientNetB0\n",
        "efficientnet_history = efficientnet_model.fit(train_data, validation_data=valid_data, epochs=50, class_weight=class_weights)\n",
        "\n",
        "# Training InceptionV3\n",
        "inceptionv3_history = inceptionv3_model.fit(train_data, validation_data=valid_data, epochs=50, class_weight=class_weights)\n",
        "\n",
        "# Training DenseNet121\n",
        "densenet_history = densenet_base.fit(train_data, validation_data=valid_data, epochs=50, class_weight=class_weights)\n"
      ],
      "metadata": {
        "id": "gRNFxfomfUSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Training, Validation Accuracy/Loss for Each Model**"
      ],
      "metadata": {
        "id": "WiVAFqrufYBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history, model_name):\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title(f'{model_name} - Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title(f'{model_name} - Training and Validation Loss')\n",
        "    plt.show()\n",
        "\n",
        "# Plot for ResNet, EfficientNet, and InceptionV3\n",
        "plot_history(resnet_history, 'ResNet50')\n",
        "plot_history(efficientnet_history, 'EfficientNetB0')\n",
        "plot_history(inceptionv3_history, 'InceptionV3')\n",
        "plot_history(densenet_history, 'DenseNet121')"
      ],
      "metadata": {
        "id": "499lFiwnfgAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate and Compare Models on Test Data**"
      ],
      "metadata": {
        "id": "QVRhQVYxfk-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def evaluate_model(model, test_data, model_name, labels):\n",
        "    # Evaluate the model on test data\n",
        "    test_loss, test_acc = model.evaluate(test_data)\n",
        "    print(f'{model_name} - Test Accuracy: {test_acc*100:.2f}%')\n",
        "\n",
        "    # Make predictions\n",
        "    Y_pred = model.predict(test_data)\n",
        "    y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(test_data.classes, y_pred)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(f'{model_name} - Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    # Classification report\n",
        "    print(f'{model_name} - Classification Report')\n",
        "    # Updated line to use the correct number of labels\n",
        "    print(classification_report(test_data.classes, y_pred, target_names=labels))\n",
        "\n",
        "    # Plot ROC curve and AUC\n",
        "    y_true = test_data.classes\n",
        "    n_classes = len(labels)\n",
        "\n",
        "    # Binarize the output labels for multi-class ROC curve\n",
        "    y_true_bin = label_binarize(y_true, classes=np.arange(n_classes))\n",
        "    if n_classes == 2:\n",
        "        fpr, tpr, _ = roc_curve(y_true, Y_pred[:, 1])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "    else:\n",
        "        # ROC curve for each class\n",
        "        for i in range(n_classes):\n",
        "            fpr, tpr, _ = roc_curve(y_true_bin[:, i], Y_pred[:, i])\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.plot(fpr, tpr, lw=2, label=f'Class {labels[i]} (area = {roc_auc:.2f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{model_name} - Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate all models (ensure 'labels' corresponds to your class names)\n",
        "# Updated labels to include 4 classes\n",
        "labels = ['adenocarcinoma', 'large-cell-carcinoma', 'squamous-cell-carcinoma', 'normal']\n",
        "# evaluate_model(resnet_model, test_data, 'ResNet50', labels)\n",
        "# evaluate_model(efficientnet_model, test_data, 'EfficientNetB0', labels)\n",
        "# evaluate_model(inceptionv3_model, test_data, 'InceptionV3', labels)\n",
        "evaluate_model(densenet_base, test_data, 'DenseNet121', labels)"
      ],
      "metadata": {
        "id": "XbbulOlbfphU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Select the Best Model**\n",
        "\n",
        "After evaluating the test accuracy of all models and reviewing the confusion matrix and classification report, select the model with the highest accuracy or performance metrics.\n"
      ],
      "metadata": {
        "id": "qJhu783hftJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Tuning (On Best Model, e.g., DenseNet 121)**"
      ],
      "metadata": {
        "id": "6SkclBvUgbmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "id": "WTGMFzJ6WsnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "from keras_tuner import RandomSearch\n",
        "\n",
        "def build_hyper_model(hp):\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dropout(hp.Float('dropout_rate', min_value=0.3, max_value=0.7, step=0.1)),\n",
        "        Dense(hp.Int('units', min_value=128, max_value=512, step=64), activation='relu'),\n",
        "        Dense(4, activation='softmax')  # 4 classes\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = RandomSearch(build_hyper_model, objective='val_accuracy', max_trials=5, executions_per_trial=1,\n",
        "                     directory='hyperparam_tuning', project_name='best_model_tuning')\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "tuner.search(train_data, validation_data=test_data, epochs=10)\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hp = tuner.get_best_hyperparameters()[0]\n",
        "print(f\"Best hyperparameters: Dropout Rate = {best_hp.get('dropout_rate')}, Units = {best_hp.get('units')}, Learning Rate = {best_hp.get('learning_rate')}\")\n"
      ],
      "metadata": {
        "id": "xTk-kjfqgf_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history, title):\n",
        "  \"\"\"Plots the training and validation accuracy and loss curves.\n",
        "\n",
        "  Args:\n",
        "    history: The training history object returned by model.fit.\n",
        "    title: The title of the plot.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 5))\n",
        "\n",
        "  # Accuracy plot\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "  plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "  plt.title(f'Model Accuracy - {title}')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(loc='lower right')\n",
        "\n",
        "  # Loss plot\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(history.history['loss'], label='Training Loss')\n",
        "  plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "  plt.title(f'Model Loss - {title}')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(loc='upper right')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2s7txKxbI_7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Hyperparameter Tuning Results**"
      ],
      "metadata": {
        "id": "dOWUikgggjZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best model from tuning\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Retrain the best model with tuned hyperparameters\n",
        "history = best_model.fit(train_data, validation_data=test_data, epochs=10)"
      ],
      "metadata": {
        "id": "BG9eLEglgm-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the results of the tuned model\n",
        "plot_history(history, 'Best Tuned DenseNet121')"
      ],
      "metadata": {
        "id": "y79UnVwlJFgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Steps: Save the Best Model**"
      ],
      "metadata": {
        "id": "OQaCcWddgsP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save('best_lung_cancer_ct_model_tuned.keras')"
      ],
      "metadata": {
        "id": "GPUAhIN-gvfa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}